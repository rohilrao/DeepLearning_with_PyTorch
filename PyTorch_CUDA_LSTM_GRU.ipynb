{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CUDA_Sheet7_Ruben_Rohil.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rX9Hzzioqp1O"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import torchvision.datasets as dsets\r\n",
        " "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIViiePQqwjF"
      },
      "source": [
        "# LSTM implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmCVhxALq6Nx"
      },
      "source": [
        "import math\r\n",
        "\r\n",
        "class myLSTM(nn.Module):\r\n",
        "    def __init__(self, input_size, hidden_size, layer_dim = 1):\r\n",
        "      super().__init__()\r\n",
        "      self.input_size = input_size\r\n",
        "      self.hidden_size = hidden_size\r\n",
        "\r\n",
        "\r\n",
        "      '''\r\n",
        "      Combining weight parameters for all gates into single matrices for faster calculation\r\n",
        "      '''\r\n",
        "      self.weight_ih = nn.Parameter(torch.Tensor(input_size, hidden_size * 4))\r\n",
        "      self.weight_hh = nn.Parameter(torch.Tensor(hidden_size, hidden_size * 4))\r\n",
        "      self.bias = nn.Parameter(torch.Tensor(hidden_size * 4))\r\n",
        "\r\n",
        "      self.init_weights()\r\n",
        "\r\n",
        "      \r\n",
        "    '''\r\n",
        "    Initialize weights similar to pytorch class\r\n",
        "    '''\r\n",
        "    def init_weights(self):\r\n",
        "      stdv = 1.0 / math.sqrt(self.hidden_size)\r\n",
        "      for weight in self.parameters():\r\n",
        "        weight.data.uniform_(-stdv, stdv)\r\n",
        "\r\n",
        "    '''\r\n",
        "    Feed forward method for lstm\r\n",
        "\r\n",
        "    INPUT x is of shape (batch_size, sequence length, feature dimension) i.e 100,28,28\r\n",
        "\r\n",
        "    OUTPUT size (hidden state) should be (batch_size , sequence length, output size) i.e 100, 28 , 128\r\n",
        "\r\n",
        "    '''\r\n",
        "\r\n",
        "    def forward(self, x, init_states):\r\n",
        "\r\n",
        "      batch_size, seq_size , feature_dim = x.size()\r\n",
        "\r\n",
        "      hidden_seq = []\r\n",
        "\r\n",
        "      # INITIALIZE HIDDEN STATES AND CONTENT FOR FIRST TIME STEP\r\n",
        "\r\n",
        "      if init_states is None:\r\n",
        "            h_t, c_t = (torch.zeros(bs,self.hidden_size).to(x.device), \r\n",
        "                        torch.zeros(bs, self.hidden_size).to(x.device))\r\n",
        "      else:\r\n",
        "            h_t, c_t = init_states\r\n",
        "\r\n",
        "\r\n",
        "      for t in range(seq_size):\r\n",
        "              x_t = x[:, t, :]\r\n",
        "\r\n",
        "              # Do all computations into a single matrix multiplication\r\n",
        "              gates = x_t @ self.weight_ih + h_t @ self.weight_hh + self.bias\r\n",
        "\r\n",
        "              #Obtain values for input, forget , update and output gates (ORDER AS PER PYTORCH DEFAULTS)\r\n",
        "              i_t, f_t, g_t, o_t = (\r\n",
        "                  torch.sigmoid(gates[:, :self.hidden_size]), # input [:,0:128]\r\n",
        "                  torch.sigmoid(gates[:, self.hidden_size:self.hidden_size*2]), # forget [:,128:256]\r\n",
        "                  torch.tanh(gates[:, self.hidden_size*2:self.hidden_size*3]),  #update [: ,256:384]\r\n",
        "                  torch.sigmoid(gates[:, self.hidden_size*3:]), # output [,384:512]\r\n",
        "              )\r\n",
        "\r\n",
        "              c_t = f_t * c_t + i_t * g_t  # Update memory content c_t\r\n",
        "              h_t = o_t * torch.tanh(c_t)  # Update hidden state\r\n",
        "              hidden_seq.append(h_t.unsqueeze(0)) # Append h_t to the hidden sequence\r\n",
        "              #print(len(hidden_seq))\r\n",
        "\r\n",
        "      hidden_seq = torch.cat(hidden_seq, dim=0) #Stack hidden sequence outputs \r\n",
        "      #print(hidden_seq.shape)\r\n",
        "      hidden_seq = hidden_seq.transpose(0, 1).contiguous() #Transpose batch_size and sequence size\r\n",
        "      #print(hidden_seq.shape)\r\n",
        "\r\n",
        "\r\n",
        "      return hidden_seq, (h_t, c_t)\r\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oG-Nh-kiuz5o"
      },
      "source": [
        "'''\r\n",
        "STEP 1: LOADING DATASET\r\n",
        "'''\r\n",
        "train_dataset = dsets.MNIST(root='./data', \r\n",
        "                            train=True, \r\n",
        "                            transform=transforms.ToTensor(),\r\n",
        "                            download=True)\r\n",
        " \r\n",
        "test_dataset = dsets.MNIST(root='./data', \r\n",
        "                           train=False, \r\n",
        "                           transform=transforms.ToTensor())\r\n",
        "\r\n",
        "'''\r\n",
        "STEP 2: MAKING DATASET ITERABLE\r\n",
        "'''\r\n",
        " \r\n",
        "batch_size = 100\r\n",
        "n_iters = 6000\r\n",
        "num_epochs = n_iters / (len(train_dataset) / batch_size)\r\n",
        "num_epochs = int(num_epochs)\r\n",
        " \r\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \r\n",
        "                                           batch_size=batch_size, \r\n",
        "                                           shuffle=True)\r\n",
        " \r\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \r\n",
        "                                          batch_size=batch_size, \r\n",
        "                                          shuffle=False)\r\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Fo8ewgbu_KX"
      },
      "source": [
        "\r\n",
        "'''\r\n",
        "STEP 3: CREATE MODEL CLASS\r\n",
        "'''\r\n",
        " \r\n",
        "class LSTMModel(nn.Module):\r\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, layer_dim):\r\n",
        "        super(LSTMModel, self).__init__()\r\n",
        "        # Hidden dimensions\r\n",
        "        self.hidden_dim = hidden_dim\r\n",
        "         \r\n",
        "        # Number of hidden layers\r\n",
        "        #self.layer_dim = layer_dim\r\n",
        "         \r\n",
        "        # Building your LSTM\r\n",
        "        # batch_first=True causes input/output tensors to be of shape\r\n",
        "        # (batch_dim, seq_dim, feature_dim)\r\n",
        "\r\n",
        "        self.lstm = myLSTM(input_dim, hidden_dim, layer_dim)\r\n",
        "                 \r\n",
        "        # Readout layer\r\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\r\n",
        "     \r\n",
        "    def forward(self, x):\r\n",
        "        # Initialize hidden state with zeros\r\n",
        "        #######################\r\n",
        "        #  USE GPU FOR MODEL  #\r\n",
        "        #######################\r\n",
        "        \r\n",
        "        #print(x.shape,\"x.shape\")100, 28, 28\r\n",
        "        if torch.cuda.is_available():\r\n",
        "            h0 = torch.zeros(x.size(0), self.hidden_dim).cuda()\r\n",
        "        else:\r\n",
        "            h0 = torch.zeros(x.size(0), self.hidden_dim)\r\n",
        "         \r\n",
        "        # Initialize cell state\r\n",
        "        if torch.cuda.is_available():\r\n",
        "            c0 = torch.zeros(x.size(0), self.hidden_dim).cuda()\r\n",
        "        else:\r\n",
        "            c0 = torch.zeros(x.size(0), self.hidden_dim)\r\n",
        "        \r\n",
        "        #Note you can also learn the h0 and c0!\r\n",
        "        out, (hn, cn) = self.lstm(x, (h0,c0))#or None!\r\n",
        "\r\n",
        "\r\n",
        "        # Index hidden state of last time step\r\n",
        "        # out.size() --> 100, 28, 128\r\n",
        "        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states! \r\n",
        "        out = self.fc(out[:, -1, :]) \r\n",
        "        # out.size() --> 100, 10\r\n",
        "\r\n",
        "        return out\r\n",
        " "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekQP5UDKvV8o"
      },
      "source": [
        "'''\r\n",
        "STEP 4: INSTANTIATE MODEL CLASS\r\n",
        "'''\r\n",
        "input_dim = 28\r\n",
        "hidden_dim = 128\r\n",
        "layer_dim = 3  # ONLY CHANGE IS HERE FROM ONE LAYER TO TWO LAYER, HERE I HAVE NOT INCLUDED ON THE MODEL CAUSE IT BECOMES HARD\r\n",
        "output_dim = 10\r\n",
        " \r\n",
        "model = LSTMModel(input_dim, hidden_dim, output_dim, layer_dim)\r\n",
        " \r\n",
        "#######################\r\n",
        "#  USE GPU FOR MODEL  #\r\n",
        "#######################\r\n",
        " \r\n",
        "if torch.cuda.is_available():\r\n",
        "    model.cuda()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZKmacCE9JX0",
        "outputId": "bd486079-1741-4a78-fe67-674cec577036"
      },
      "source": [
        "model"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMModel(\n",
              "  (lstm): myLSTM()\n",
              "  (fc): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRnSfYjzvmJT"
      },
      "source": [
        "'''\r\n",
        "STEP 5: INSTANTIATE LOSS CLASS\r\n",
        "'''\r\n",
        "criterion = nn.CrossEntropyLoss().cuda()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_jAYSa0ve7c"
      },
      "source": [
        "'''\r\n",
        "STEP 6: INSTANTIATE OPTIMIZER CLASS\r\n",
        "'''\r\n",
        "learning_rate = 0.1\r\n",
        " \r\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwSOYzxUvsPg",
        "outputId": "2832dd4e-2527-4413-a905-2edf44edbdec"
      },
      "source": [
        "'''\r\n",
        "STEP 7: TRAIN THE MODEL\r\n",
        "'''\r\n",
        "\r\n",
        "# Number of steps to unroll\r\n",
        "seq_dim = 28 \r\n",
        " \r\n",
        "iter = 0\r\n",
        "for epoch in range(num_epochs):\r\n",
        "    for i, (images, labels) in enumerate(train_loader):\r\n",
        "        # Load images as Variable\r\n",
        "        #######################\r\n",
        "        #  USE GPU FOR MODEL  #\r\n",
        "        #######################\r\n",
        "        if torch.cuda.is_available():\r\n",
        "            images = images.view(-1, seq_dim, input_dim).cuda()\r\n",
        "            labels = labels.cuda()\r\n",
        "        else:\r\n",
        "            images = images.view(-1, seq_dim, input_dim)\r\n",
        "\r\n",
        "             \r\n",
        "        # Clear gradients w.r.t. parameters\r\n",
        "        optimizer.zero_grad()\r\n",
        "         \r\n",
        "        # Forward pass to get output/logits\r\n",
        "        # outputs.size() --> 100, 10\r\n",
        "        outputs = model(images)\r\n",
        "         \r\n",
        "        # Calculate Loss: softmax --> cross entropy loss\r\n",
        "        loss = criterion(outputs, labels)\r\n",
        "         \r\n",
        "        # Getting gradients w.r.t. parameters\r\n",
        "        loss.backward()\r\n",
        "         \r\n",
        "        # Updating parameters\r\n",
        "        optimizer.step()\r\n",
        "         \r\n",
        "        iter += 1\r\n",
        "         \r\n",
        "        if iter % 500 == 0:\r\n",
        "            # Calculate Accuracy         \r\n",
        "            correct = 0\r\n",
        "            total = 0\r\n",
        "            # Iterate through test dataset\r\n",
        "            for images, labels in test_loader:\r\n",
        "                #######################\r\n",
        "                #  USE GPU FOR MODEL  #\r\n",
        "                #######################\r\n",
        "                if torch.cuda.is_available():\r\n",
        "                    images = images.view(-1, seq_dim, input_dim).cuda()\r\n",
        "\r\n",
        "                 \r\n",
        "                # Forward pass only to get logits/output\r\n",
        "                outputs = model(images)\r\n",
        "                 \r\n",
        "                # Get predictions from the maximum value\r\n",
        "                _, predicted = torch.max(outputs.data, 1)\r\n",
        "                 \r\n",
        "                # Total number of labels\r\n",
        "                total += labels.size(0)\r\n",
        "                 \r\n",
        "                # Total correct predictions\r\n",
        "                #######################\r\n",
        "                #  USE GPU FOR MODEL  #\r\n",
        "                #######################\r\n",
        "                if torch.cuda.is_available():\r\n",
        "                    correct += (predicted.cpu() == labels.cpu()).sum()\r\n",
        "                else:\r\n",
        "                    correct += (predicted == labels).sum()\r\n",
        "             \r\n",
        "            accuracy = 100 * correct / total\r\n",
        "             \r\n",
        "            # Print Loss\r\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))\r\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 500. Loss: 2.2723288536071777. Accuracy: 18.920000076293945\n",
            "Iteration: 1000. Loss: 1.1944184303283691. Accuracy: 59.459999084472656\n",
            "Iteration: 1500. Loss: 0.6594192385673523. Accuracy: 73.30999755859375\n",
            "Iteration: 2000. Loss: 0.5093726515769958. Accuracy: 88.20999908447266\n",
            "Iteration: 2500. Loss: 0.216352179646492. Accuracy: 92.79000091552734\n",
            "Iteration: 3000. Loss: 0.16063569486141205. Accuracy: 93.87999725341797\n",
            "Iteration: 3500. Loss: 0.15129585564136505. Accuracy: 96.05999755859375\n",
            "Iteration: 4000. Loss: 0.1264088898897171. Accuracy: 96.6500015258789\n",
            "Iteration: 4500. Loss: 0.05556895583868027. Accuracy: 96.5199966430664\n",
            "Iteration: 5000. Loss: 0.2652735412120819. Accuracy: 97.18000030517578\n",
            "Iteration: 5500. Loss: 0.08962659537792206. Accuracy: 97.2300033569336\n",
            "Iteration: 6000. Loss: 0.12946972250938416. Accuracy: 97.58999633789062\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypMRi5kVv15Y"
      },
      "source": [
        ""
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9SePtoCLTGD"
      },
      "source": [
        "# GRU implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S60IrSwOLWtP"
      },
      "source": [
        "import math\r\n",
        "\r\n",
        "class myGRU(nn.Module):\r\n",
        "    def __init__(self, input_size, hidden_size, layer_dim = 1):\r\n",
        "        super().__init__()\r\n",
        "        self.input_size = input_size\r\n",
        "        self.hidden_size = hidden_size\r\n",
        "\r\n",
        "\r\n",
        "        '''\r\n",
        "        Combining weight parameters for all gates into single matrices for faster calculation\r\n",
        "        '''\r\n",
        "        self.weight_ih = nn.Parameter(torch.Tensor(input_size, hidden_size * 4))\r\n",
        "        self.weight_hh = nn.Parameter(torch.Tensor(hidden_size, hidden_size * 4))\r\n",
        "        self.bias = nn.Parameter(torch.Tensor(hidden_size * 4))\r\n",
        "\r\n",
        "        self.init_weights()\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    def init_weights(self):\r\n",
        "        stdv = 1.0 / math.sqrt(self.hidden_size)\r\n",
        "        for weight in self.parameters():\r\n",
        "            weight.data.uniform_(-stdv, stdv)\r\n",
        "\r\n",
        "    \r\n",
        "    def forward(self, x, init_states=None):\r\n",
        "\r\n",
        "        \"\"\"Assumes x is of shape (batch, sequence, feature)\"\"\"\r\n",
        "\r\n",
        "        batch_size, seq_size , feature_dim = x.size()\r\n",
        "\r\n",
        "        hidden_seq = []\r\n",
        "\r\n",
        "        if init_states is None:\r\n",
        "            h_t, c_t = (torch.zeros(bs,self.hidden_size).to(x.device), \r\n",
        "                        torch.zeros(bs, self.hidden_size).to(x.device))\r\n",
        "        else:\r\n",
        "            h_t, c_t = init_states\r\n",
        " \r\n",
        "\r\n",
        "        for t in range(seq_size):\r\n",
        "            x_t = x[:, t, :]\r\n",
        "\r\n",
        "            # Do all the computations into a single matrix multiplication\r\n",
        "            gates = x_t @ self.weight_ih + h_t @ self.weight_hh\r\n",
        "\r\n",
        "            z_t, r_t = (\r\n",
        "                torch.sigmoid(gates[:, :self.hidden_size]), # input\r\n",
        "                torch.sigmoid(gates[:, self.hidden_size:self.hidden_size*2]), # forget\r\n",
        "            )\r\n",
        "\r\n",
        "        \r\n",
        "            h_cap = torch.tanh(x_t @ self.weight_ih +  self.weight_hh @ (r_t*h_t) )\r\n",
        "\r\n",
        "            h_t = (1-z_t)*h_t + z_t*h_cap\r\n",
        "            hidden_seq.append(h_t.unsqueeze(0))\r\n",
        "        hidden_seq = torch.cat(hidden_seq, dim=0)\r\n",
        "        # reshape from shape (sequence, batch, feature) to (batch, sequence, feature)\r\n",
        "        hidden_seq = hidden_seq.transpose(0, 1).contiguous()\r\n",
        "\r\n",
        "        return hidden_seq, (h_t, c_t)\r\n",
        "                   "
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rb7KfraRyHm"
      },
      "source": [
        "'''\r\n",
        "STEP 1: LOADING DATASET\r\n",
        "'''\r\n",
        "train_dataset = dsets.MNIST(root='./data', \r\n",
        "                            train=True, \r\n",
        "                            transform=transforms.ToTensor(),\r\n",
        "                            download=True)\r\n",
        " \r\n",
        "test_dataset = dsets.MNIST(root='./data', \r\n",
        "                           train=False, \r\n",
        "                           transform=transforms.ToTensor())\r\n",
        " \r\n",
        "'''\r\n",
        "STEP 2: MAKING DATASET ITERABLE\r\n",
        "'''\r\n",
        " \r\n",
        "batch_size = 100\r\n",
        "n_iters = 6000\r\n",
        "num_epochs = n_iters / (len(train_dataset) / batch_size)\r\n",
        "num_epochs = int(num_epochs)\r\n",
        " \r\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \r\n",
        "                                           batch_size=batch_size, \r\n",
        "                                           shuffle=True)\r\n",
        " \r\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \r\n",
        "                                          batch_size=batch_size, \r\n",
        "                                          shuffle=False)\r\n",
        "\r\n",
        "'''\r\n",
        "STEP 3: CREATE MODEL CLASS\r\n",
        "'''\r\n",
        " \r\n",
        "class GRUModel(nn.Module):\r\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\r\n",
        "        super(GRUModel, self).__init__()\r\n",
        "        # Hidden dimensions\r\n",
        "        self.hidden_dim = hidden_dim\r\n",
        "         \r\n",
        "         \r\n",
        "        # Building your LSTM\r\n",
        "        # batch_first=True causes input/output tensors to be of shape\r\n",
        "        # (batch_dim, seq_dim, feature_dim)\r\n",
        "        self.gru = myGRU(input_dim, hidden_dim)\r\n",
        "                 \r\n",
        "        # Readout layer\r\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\r\n",
        "     \r\n",
        "    def forward(self, x):\r\n",
        "        # Initialize hidden state with zeros\r\n",
        "        #######################\r\n",
        "        #  USE GPU FOR MODEL  #\r\n",
        "        #######################\r\n",
        "        \r\n",
        "        #print(x.shape,\"x.shape\")100, 28, 28\r\n",
        "        if torch.cuda.is_available():\r\n",
        "            h0 = torch.zeros(x.size(0), self.hidden_dim).cuda()\r\n",
        "        else:\r\n",
        "            h0 = torch.zeros(x.size(0), self.hidden_dim)\r\n",
        "         \r\n",
        "        # Initialize cell state\r\n",
        "        if torch.cuda.is_available():\r\n",
        "            c0 = torch.zeros(x.size(0), self.hidden_dim).cuda()\r\n",
        "        else:\r\n",
        "            c0 = torch.zeros(x.size(0), self.hidden_dim)\r\n",
        "        \r\n",
        "        #Note you can also learn the h0 and c0!\r\n",
        "        out, (hn, cn) = self.gru(x, (h0,c0))#or None!\r\n",
        "\r\n",
        "        # Index hidden state of last time step\r\n",
        "        # out.size() --> 100, 28, 100\r\n",
        "        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states! \r\n",
        "        out = self.fc(out[:, -1, :]) \r\n",
        "        # out.size() --> 100, 10\r\n",
        "\r\n",
        "        return out\r\n",
        "\r\n",
        "\r\n",
        " \r\n",
        "'''\r\n",
        "STEP 4: INSTANTIATE MODEL CLASS\r\n",
        "'''\r\n",
        "input_dim = 28\r\n",
        "hidden_dim = 100\r\n",
        "layer_dim = 1  # ONLY CHANGE IS HERE FROM ONE LAYER TO TWO LAYER\r\n",
        "output_dim = 10\r\n",
        " \r\n",
        "model = LSTMModel(input_dim, hidden_dim, output_dim, layer_dim)\r\n",
        "\r\n",
        "\r\n",
        "#######################\r\n",
        "#  USE GPU FOR MODEL  #\r\n",
        "#######################\r\n",
        " \r\n",
        "if torch.cuda.is_available():\r\n",
        "    model.cuda()\r\n",
        "     \r\n",
        "'''\r\n",
        "STEP 5: INSTANTIATE LOSS CLASS\r\n",
        "'''\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        " \r\n",
        "'''\r\n",
        "STEP 6: INSTANTIATE OPTIMIZER CLASS\r\n",
        "'''\r\n",
        "learning_rate = 0.1\r\n",
        " \r\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \r\n",
        " "
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kl-aTf2oSQp6",
        "outputId": "8c7d35b2-d24f-4f2f-d570-b692e00cb556"
      },
      "source": [
        "'''\r\n",
        "STEP 7: TRAIN THE MODEL\r\n",
        "'''\r\n",
        " \r\n",
        "# Number of steps to unroll\r\n",
        "seq_dim = 28 \r\n",
        " \r\n",
        "iter = 0\r\n",
        "for epoch in range(num_epochs):\r\n",
        "    for i, (images, labels) in enumerate(train_loader):\r\n",
        "        # Load images as Variable\r\n",
        "        #######################\r\n",
        "        #  USE GPU FOR MODEL  #\r\n",
        "        #######################\r\n",
        "        if torch.cuda.is_available():\r\n",
        "            images = images.view(-1, seq_dim, input_dim).cuda()\r\n",
        "            labels = labels.cuda()\r\n",
        "        else:\r\n",
        "            images = images.view(-1, seq_dim, input_dim)\r\n",
        "\r\n",
        "             \r\n",
        "        # Clear gradients w.r.t. parameters\r\n",
        "        optimizer.zero_grad()\r\n",
        "         \r\n",
        "        # Forward pass to get output/logits\r\n",
        "        # outputs.size() --> 100, 10\r\n",
        "        outputs = model(images)\r\n",
        "         \r\n",
        "        # Calculate Loss: softmax --> cross entropy loss\r\n",
        "        loss = criterion(outputs, labels)\r\n",
        "         \r\n",
        "        # Getting gradients w.r.t. parameters\r\n",
        "        loss.backward()\r\n",
        "         \r\n",
        "        # Updating parameters\r\n",
        "        optimizer.step()\r\n",
        "         \r\n",
        "        iter += 1\r\n",
        "         \r\n",
        "        if iter % 500 == 0:\r\n",
        "            # Calculate Accuracy         \r\n",
        "            correct = 0\r\n",
        "            total = 0\r\n",
        "            # Iterate through test dataset\r\n",
        "            for images, labels in test_loader:\r\n",
        "                #######################\r\n",
        "                #  USE GPU FOR MODEL  #\r\n",
        "                #######################\r\n",
        "                if torch.cuda.is_available():\r\n",
        "                    images = images.view(-1, seq_dim, input_dim).cuda()\r\n",
        "\r\n",
        "                 \r\n",
        "                # Forward pass only to get logits/output\r\n",
        "                outputs = model(images)\r\n",
        "                 \r\n",
        "                # Get predictions from the maximum value\r\n",
        "                _, predicted = torch.max(outputs.data, 1)\r\n",
        "                 \r\n",
        "                # Total number of labels\r\n",
        "                total += labels.size(0)\r\n",
        "                 \r\n",
        "                # Total correct predictions\r\n",
        "                #######################\r\n",
        "                #  USE GPU FOR MODEL  #\r\n",
        "                #######################\r\n",
        "                if torch.cuda.is_available():\r\n",
        "                    correct += (predicted.cpu() == labels.cpu()).sum()\r\n",
        "                else:\r\n",
        "                    correct += (predicted == labels).sum()\r\n",
        "             \r\n",
        "            accuracy = 100 * correct / total\r\n",
        "             \r\n",
        "            # Print Loss\r\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 500. Loss: 2.264110803604126. Accuracy: 19.3799991607666\n",
            "Iteration: 1000. Loss: 1.3947224617004395. Accuracy: 58.91999816894531\n",
            "Iteration: 1500. Loss: 0.47112739086151123. Accuracy: 84.30000305175781\n",
            "Iteration: 2000. Loss: 0.2999100387096405. Accuracy: 91.75\n",
            "Iteration: 2500. Loss: 0.21244826912879944. Accuracy: 93.95999908447266\n",
            "Iteration: 3000. Loss: 0.18665264546871185. Accuracy: 94.18000030517578\n",
            "Iteration: 3500. Loss: 0.2370314598083496. Accuracy: 95.54000091552734\n",
            "Iteration: 4000. Loss: 0.189910426735878. Accuracy: 95.01000213623047\n",
            "Iteration: 4500. Loss: 0.19920867681503296. Accuracy: 96.43000030517578\n",
            "Iteration: 5000. Loss: 0.11613094061613083. Accuracy: 96.93000030517578\n",
            "Iteration: 5500. Loss: 0.0599500946700573. Accuracy: 96.94999694824219\n",
            "Iteration: 6000. Loss: 0.052838120609521866. Accuracy: 96.5199966430664\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}